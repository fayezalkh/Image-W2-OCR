# -*- coding: utf-8 -*-
"""W2 OCR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S9XMdBhRx-PR34yPJmXTxtuDrMVnTGdV
"""

import os

# Check if train.zip exists
if os.path.exists('/content/train.zip'):
    print('Unzipping train.zip...')
    !unzip /content/train.zip -d /content/
    print('Unzipping complete.')
else:
    print('train.zip not found in /content/. Please ensure the file is uploaded.')

!pip install pytesseract
!sudo apt-get install tesseract-ocr

import cv2
import numpy as np
import pytesseract
import pandas as pd
import os
import re
from statistics import mean, median, mode
from pytesseract import Output

# ---------------- CONFIGURATION ---------------- #

pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract' # Updated path for Colab environment

IMAGE_DIR = "/content/train/images/"
GROUND_TRUTH_DIR = "/content/train/boxes_transcripts_labels/"

SINGLE_IMAGE_MODE = False   # ← Switch between modes

SINGLE_IMAGE_PATH = "data/images/sample.jpg"

# ------------------------------------------------- #

def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    return text

def correct_skew(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150, apertureSize=3)
    lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)

    angles = []
    if lines is not None:
        for line in lines:
            rho, theta = line[0]
            angle = (theta * 180 / np.pi) - 90
            if -45 < angle < 45:
                angles.append(angle)

    skew_angle = np.median(angles) if angles else 0

    (h, w) = img.shape[:2]
    center = (w // 2, h // 2)
    rotation_matrix = cv2.getRotationMatrix2D(center, skew_angle, 1.0)

    rotated_img = cv2.warpAffine(
        img,
        rotation_matrix,
        (w, h),
        flags=cv2.INTER_CUBIC,
        borderMode=cv2.BORDER_REPLICATE
    )

    return rotated_img, skew_angle

def preprocess_image(img):
    rotated_img, skew_angle = correct_skew(img)
    gray = cv2.cvtColor(rotated_img, cv2.COLOR_BGR2GRAY)
    den_img = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)
    return den_img, skew_angle

def load_ground_truth(gt_path):
    gt_data = pd.read_csv(gt_path, sep='\t')

    structured_data = []
    for row in gt_data.iloc[:, 0]:
        parts = row.split(',')
        if len(parts) >= 7:
            structured_data.append(parts[:7])

    gt_parsed = pd.DataFrame(structured_data, columns=[
        "x1", "y1", "x2", "y2", "x3", "y3", "text"
    ])

    return gt_parsed['text'].dropna().tolist()

def run_ocr(den_img):
    ocr_data = pytesseract.image_to_data(den_img, output_type=Output.DICT)
    ocr_words = [word.strip() for word in ocr_data['text'] if word.strip()]
    return ocr_data, ocr_words

# ---------------- SINGLE IMAGE MODE ---------------- #

if SINGLE_IMAGE_MODE:

    img = cv2.imread(SINGLE_IMAGE_PATH)

    if img is None:
        print("Failed to load image.")
        exit()

    den_img, skew_angle = preprocess_image(img)
    ocr_data, ocr_words = run_ocr(den_img)

    print(f"Detected Skew Angle: {skew_angle:.2f}°")
    print("\nOCR Output:")
    print(pytesseract.image_to_string(den_img))

# ---------------- DATASET LOOP MODE ---------------- #

else:

    all_accuracies = []
    true_positives = 0
    false_positives = 0
    false_negatives = 0

    image_files = os.listdir(IMAGE_DIR)

    for idx, image_file in enumerate(image_files):

        image_path = os.path.join(IMAGE_DIR, image_file)
        gt_path = os.path.join(
            GROUND_TRUTH_DIR,
            f"{os.path.splitext(image_file)[0]}.tsv"
        )

        if not os.path.exists(gt_path):
            print(f"Missing GT for {image_file}")
            continue

        img = cv2.imread(image_path)
        if img is None:
            continue

        den_img, skew_angle = preprocess_image(img)
        ground_truth_words = load_ground_truth(gt_path)

        ocr_data, ocr_words = run_ocr(den_img)

        matches = [word for word in ocr_words if word in ground_truth_words]

        false_positives += len(ocr_words) - len(matches)
        false_negatives += len(ground_truth_words) - len(matches)
        true_positives += len(matches)

        accuracy = (
            len(matches) / len(ground_truth_words) * 100
            if ground_truth_words else 0
        )

        all_accuracies.append(accuracy)

        print(f"{idx+1}/{len(image_files)} | {image_file} | {accuracy:.2f}%")

    precision = true_positives / (true_positives + false_positives)
    recall = true_positives / (true_positives + false_negatives)
    f1_score = 2 * (precision * recall) / (precision + recall)

    print("\nOverall Metrics:")
    print(f"Mean Accuracy: {mean(all_accuracies):.2f}%")
    print(f"Median Accuracy: {median(all_accuracies):.2f}%")
    print(f"Precision: {precision:.2f}")
    print(f"Recall: {recall:.2f}")
    print(f"F1 Score: {f1_score:.2f}")